{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcVsVWOhv6A3"
      },
      "source": [
        "# GenAI-Powered RAG Assistant for \"Fundamentals of Electric Circuits\"\n",
        "\n",
        "This notebook showcases a Retrieval-Augmented Generation (RAG) assistant built using the textbook **Fundamentals of Electric Circuits by Alexandar and Sadiku**. This assistant allow users to ask questions and receive accurate, grounded answers directly from the book’s content.\n",
        "\n",
        "The system leverages the power of **Google's Gemini API**, **text embeddings**, and **ChromaDB** to retrieve and generate responses. It also supports **chapter-wise summarization** and **structured JSON output** for seamless integration with apps or UIs.\n",
        "\n",
        "## Features\n",
        "- Text cleaning and preprocessing\n",
        "- Chunking by chapters with metadata\n",
        "- Semantic embeddings using `models/text-embedding-004`\n",
        "- Vector storage in ChromaDB\n",
        "- Question Answering using RAG\n",
        "- Structured JSON Output for clean, readable answers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuMtCjrm7W4U"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tDpj0p7vfUuH"
      },
      "outputs": [],
      "source": [
        "!pip install pymupdf\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "diYMyFYFVHnI",
        "outputId": "a89bcccc-5dad-4e48-8d66-5b77a4d28f7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from IPython.display import Markdown\n",
        "\n",
        "genai.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBiKwVBHVkl9"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(\n",
        "    api_key=userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrY2iacEWEBe"
      },
      "outputs": [],
      "source": [
        "from google.api_core import retry\n",
        "\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "if not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n",
        "  genai.models.Models.generate_content = retry.Retry(\n",
        "      predicate=is_retriable)(genai.models.Models.generate_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqzkFwt1kPZI"
      },
      "source": [
        "# Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Loading the text file"
      ],
      "metadata": {
        "id": "zWAfSfi4irkw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJboOQ-TZdCi"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "doc = kagglehub.dataset_download(\"syedsharjeelnajam/fundamentals-of-electric-circuits\")\n",
        "\n",
        "import fitz\n",
        "\n",
        "doc = fitz.open('/content/drive/MyDrive/Colab Notebooks/Fundamentals_of_Electric_Circuits.txt')\n",
        "all_pages = [page.get_text() for page in doc]\n",
        "doc.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Cleaning text file by removing extra spaces, figures, Characters, Headers"
      ],
      "metadata": {
        "id": "xHeB_djxizyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R2KlumsfzIg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove multiple newlines\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "\n",
        "    # Remove page numbers, figure/table labels\n",
        "    text = re.sub(r'Figure\\s+\\d+\\.\\d+|Table\\s+\\d+\\.\\d+', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove weird non-ASCII characters and formatting\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "\n",
        "    # Remove numbered headers like \"Chapter 1\", \"Section 1.1\"\n",
        "    text = re.sub(r'(Chapter|Section)\\s+\\d+(\\.\\d+)?', '', text)\n",
        "\n",
        "    # Strip leading/trailing whitespace from lines\n",
        "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
        "\n",
        "    # Replace 2+ line breaks with just one\n",
        "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
        "\n",
        "    # Remove line breaks in the middle of sentences\n",
        "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
        "\n",
        "    return '\\n'.join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The Cleaned text file is stored in list `texts`"
      ],
      "metadata": {
        "id": "twkEqFz1jMi0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt2bwt8MgOtI"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "for page in all_pages:\n",
        "  texts.append(clean_text(page))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_A1J9U_kYkD"
      },
      "source": [
        "# Function Embedding the Document"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Embedding** refers to the process of converting words, sentences, or documents into numerical vectors that capture their meaning, allowing AI models to understand and compare them semantically."
      ],
      "metadata": {
        "id": "rzabMgc6jJny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwELtdVGgZiW"
      },
      "outputs": [],
      "source": [
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "from google.genai import types\n",
        "# Define a helper to retry when per-minute quota is reached.\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykWWS2X2kkYp"
      },
      "outputs": [],
      "source": [
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    doc_mode = True\n",
        "    def __call__(self, input: texts) -> Embeddings:\n",
        "        if self.doc_mode:\n",
        "            task = \"retrieval_document\"\n",
        "        else:\n",
        "            task = \"retrieval_query\"\n",
        "\n",
        "        response = client.models.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            contents=input,\n",
        "            config=types.EmbedContentConfig(\n",
        "                task_type=task,\n",
        "            ),\n",
        "        )\n",
        "        return [e.values for e in response.embeddings]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqWgGOWUYLMn"
      },
      "source": [
        "# Converting text file into Vector Database (ChromaDB)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Vector storage** is a system that stores text as numerical vectors (embeddings) and allows for fast similarity search. Instead of searching for exact words, it finds content that’s semantically similar based on meaning."
      ],
      "metadata": {
        "id": "Z4MVDXImkDgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ChromaDB** is an open-source vector database designed to store embeddings and perform fast, efficient similarity searches on them."
      ],
      "metadata": {
        "id": "pvFdCNR9kNlg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPto6gQMXb5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ad9673-d9a0-4f55-e4d7-d6e43176d3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5749448b4aba>:5: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
            "  embed_fn = GeminiEmbeddingFunction()\n"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "\n",
        "DB_NAME = \"fundamentals_of_electric_circuits\"\n",
        "\n",
        "embed_fn = GeminiEmbeddingFunction()\n",
        "embed_fn.doc_mode = True\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "collection = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
        "\n",
        "# Define batch size\n",
        "BATCH_SIZE = 100  # Adjust this based on the API limit\n",
        "\n",
        "# Split the texts list into batches\n",
        "for i in range(0, len(texts), BATCH_SIZE):\n",
        "    batch_texts = texts[i : i + BATCH_SIZE]\n",
        "    batch_ids = [str(j) for j in range(i, i + len(batch_texts))]\n",
        "\n",
        "    # Embed and add the batch to the collection\n",
        "    collection.add(documents=batch_texts, ids=batch_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for successful updation of data into Vector Storage"
      ],
      "metadata": {
        "id": "3wp4yY46kiHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orOUtNdmZLRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb3b5eb-64db-422c-c452-a635c317b469"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3655"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "collection.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fzQjMBEmo4x"
      },
      "source": [
        "# Functions (Tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Functions or tools** are real code functions that you define and you let the GenAI model call them automatically when needed."
      ],
      "metadata": {
        "id": "RR1DAOPXkthm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUH7TqtpmsT_"
      },
      "outputs": [],
      "source": [
        "chap_detail = {'Chapters': ['Chapter 1', 'Chapter 2', 'Chapter 3', 'Chapter 4', 'Chapter 5', 'Chapter 6', 'Chapter 7', 'Chapter 8', 'Chapter 9',\n",
        "                            'Chapter 10', 'Chapter 11', 'Chapter 12', 'Chapter 13', 'Chapter 14', 'Chapter 15', 'Chapter 16', 'Chapter 17', 'Chapter 18',\n",
        "                            'Chapter 19'],\n",
        "               'Names': ['Basic Concepts', 'Basic Laws', 'Methods of Analysis', 'Circuit Theorems', 'Operational Amplifier', 'Capacitors & Inductor',\n",
        "                         'First Order Circuits', 'Second Order Circuits', 'Sinusoids & Phasors', 'Sinusoidal Steady State Analysis', 'AC Power Analysis',\n",
        "                         'Three Phase Circuits', 'Magnetically Coupled Circuits', 'Frequency Response', 'Introduction to Laplace Transform',\n",
        "                         'Applications of Laplace Transform', 'The Fourier Series', 'Fourier Transform', 'Two Port Networks',]\n",
        "               }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WAjz2PnbNPV"
      },
      "source": [
        "# Retrieval Process"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Retrieval Process** refers to the process of processing query by user and producing the AI-generated response"
      ],
      "metadata": {
        "id": "7GqcnhVblFQI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYeNVSazbHdt"
      },
      "outputs": [],
      "source": [
        "embed_fn.doc_mode = False\n",
        "\n",
        "query = \"Explain Fourier Analysis\"\n",
        "result = collection.query(query_texts=[query], n_results=5)\n",
        "[all_passages] = result[\"documents\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Prompt** is the set of instructions given to the model after producing the answer or result. It tells them their role, how to handle different types of quereies, and how to answer"
      ],
      "metadata": {
        "id": "iqkN_z5tlYb1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn71V1-Qbyr4"
      },
      "outputs": [],
      "source": [
        "query_oneline = query.replace(\"\\n\", \" \")\n",
        "db_tools = [chap_detail]\n",
        "prompt = f\"\"\"You are a textbook assistant answering questions using \"Fundamentals of Electric Circuits\". Use the context below and return your answer in this JSON format:\n",
        "Then answer in following format\n",
        "'answer': '', 'source_chapter': '', \"keywords\": ['', '']\n",
        "\n",
        "Question: {query_oneline}\"\"\"\n",
        "\n",
        "for passage in all_passages:\n",
        "    passage_oneline = passage.replace(\"\\n\", \" \")\n",
        "    prompt += f\"PASSAGE: {passage_oneline}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtU-J6KudpLo"
      },
      "outputs": [],
      "source": [
        "answer = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **JSON (JavaScript Object Notation)** is a lightweight format used to structure data in a way that other apps or UIs can display it easily"
      ],
      "metadata": {
        "id": "chVsA_Gfl1mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "raw_text = answer.text.strip()\n",
        "\n",
        "if raw_text.startswith(\"```json\"):\n",
        "    raw_text = raw_text[7:]\n",
        "if raw_text.endswith(\"```\"):\n",
        "    raw_text = raw_text[:-3]\n",
        "data = json.loads(raw_text)\n",
        "Markdown(data['answer'])"
      ],
      "metadata": {
        "id": "i_jZD-cFeFZr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "0c9109d3-5520-4303-96e3-7a695e8180ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Fourier analysis is a mathematical tool that represents a periodic function \\(f(t)\\) as a sum of a DC component and an AC component, which consists of an infinite series of harmonic sinusoids. The exponential Fourier series describes the spectrum of \\(f(t)\\) using the amplitude and phase angle of AC components at positive and negative harmonic frequencies."
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qubefAg5wSgv"
      },
      "source": [
        "# Project Summary\n",
        "\n",
        "This project demonstrates a practical application of Generative AI using RAG to create a smart textbook assistant.\n",
        "\n",
        "## What Was Built:\n",
        "- Cleaned and chunked the full **Fundamentals of Electric Circuits** textbook\n",
        "- Stored document chunks in **ChromaDB** with metadata per chapter\n",
        "- Used **text embeddings** from Gemini to enable semantic search\n",
        "- Built a **RAG system** to generate accurate, book-based answers\n",
        "- Added **structured JSON output** to make responses usable in apps\n",
        "\n",
        "## GenAI Capabilities Demonstrated:\n",
        "- **Embeddings**\n",
        "- **Retrieval-Augmented Generation (RAG)**\n",
        "- **Vector Search (ChromaDB)**\n",
        "- **Document Understanding**\n",
        "- **Structured Output / JSON Mode**\n",
        "\n",
        "## Next Steps:\n",
        "- Add user interface (e.g., Streamlit or chatbot)\n",
        "- Enable multi-turn memory or context caching\n",
        "- Expand to multi-book support or cross-referencing\n",
        "\n",
        "This notebook is part of the **Google x Kaggle GenAI Intensive Course Capstone (2025Q1)** and demonstrates applied GenAI in education.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "collapsed_sections": [
        "JuMtCjrm7W4U",
        "uqzkFwt1kPZI",
        "a_A1J9U_kYkD",
        "gqWgGOWUYLMn",
        "1fzQjMBEmo4x",
        "5WAjz2PnbNPV"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}